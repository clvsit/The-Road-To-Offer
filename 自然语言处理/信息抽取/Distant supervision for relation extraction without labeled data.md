用于诸如 ACE 之类的任务的关系提取的现代模型是基于从小型手工标记语料库的关系的监督学习中获得的。作者研究了一种替代范例，该范例不需要标记语料库，避免了 ACE 风格算法的域依赖性，并允许使用任何大小的语料库。作者的实验使用 Freebase（一个具有数千个关系的大型语义数据库）提供远程监督。对于出现在某个 Freebase 关系中的每一对实体，作者在一个大型的未标记语料库中找到所有包含这些实体的句子，并提取文本特征以训练关系分类器。作者的算法结合了有监督的 IE（在概率分类器中结合了 40 万个噪声模式特征）和无监督的 IE（从任何域的大型语料库中提取大量关系）的优势。作者的模型能够以 67.6％ 的精度提取 102 个关系的 10,000 个实例。作者还分析了特征性能，这表明语法分析特征对于表达中模棱两可或词汇上距离遥远的关系特别有用。

## 介绍
至少三个学习范例已应用于从文本中提取关系事实的任务（例如，了解到某个人被某个特定组织雇用，或者一个地理实体位于特定区域中）。

在监督方法中，首先对语料库中的句子进行手工标记，以说明实体的存在及其之间的关系。例如，NIST 自动内容提取（ACE）RDC 2003 和 2004 语料库包括 1000 多个文档，其中成对的实体被标记为 5 至 7 个主要关系类型和 23 至 24 个子关系，总共 16771 个关系实例。然后，ACE 系统提取各种各样的词汇，句法和语义特征，并使用监督分类器来标记测试集中句子中给定实体对之间的关系，可选地组合关系。

但是，监督关系提取存在许多问题。标记训练数据生产成本高昂，因此数量有限。同样，由于关系是在特定的语料库上标记的，因此所得的分类器偏向于特定文本域。

另一种方法是，完全无监督的信息提取，在大量文本中的实体之间提取单词字符串，然后对这些单词字符串进行聚类和简化，以生成关系字符串。无监督方法可能会使用大量数据并提取大量关系，但是生成的关系可能不容易映射到特定知识库所需的关系。

第三种方法是使用极少数的种子实例或模式进行引导学习。这些种子与大型语料库一起使用，以迭代方式提取一组新的模式，这些模式用于提取更多实例，这些实例用于提取更多模式。产生的模式通常遭受精度低和语义漂移的困扰。

作者提出了另一种范式，即远程监督，它结合了每种方法的一些优点。远程监督是 Snow 等人使用的范式的扩展，利用 WordNet 来提取实体之间的上位词（is-a）关系，类似于在生物信息学中使用弱标记数据。作者的算法使用 Freebase 为关系提取提供远程监督。 

远程监督的直觉是：**任何包含一对参与已知 Freebase 关系的实体的句子都可能以某种方式表达该关系**。由于可能有许多句子包含给定的实体对，因此我们可以提取在逻辑回归分类器中组合的大量（可能有噪声的）特征。

因此，尽管有监督的训练范例使用只有 17,000 个关系实例的小标签语料作为训练数据，但是作者的算法可以使用大量的数据：更多的文本，更多的关系和更多的实例。作者使用 120 万个 Wikipedia 文章和 180 万个实例，建立了连接 940,000 个实体的 102 个关系。此外，在大型分类器中组合大量特征有助于消除不良特征的问题。

因为作者的算法是由数据库而不是标签文本来监督的，所以它不会遭受困扰监督系统的过拟合和领域依赖性问题。通过数据库进行监督还意味着，与无监督方法不同，我们的分类器输出使用规范名称来表示关系。

作者的范例提供了一种自然的方式，可以整合来自多个句子的数据来确定两个实体之间是否存在关系。因为作者的算法可以使用大量未标记的数据，所以一对实体可能会在测试集中多次出现。对于每对实体，作者将来自该对出现的许多不同句子的特征汇总到单个特征向量中，从而能够为分类器提供更多信息，获得更准确的标签。

![Table 1](https://raw.githubusercontent.com/clvsit/markdown-image/master/nlp/task/event_extraction/Distant%20Supervision%20Table1.png)

表 1 显示了系统提取的关系实例的情况。作者还使用该系统来研究关系提取中句法与词汇（单词序列）特征的价值。虽然已知在使用干净的手工标记的 ACE 数据上，句法功能可以改善监督的 IE 的性能，但我们不知道语法特征是否可以改善无监督或远程监督的 IE。先前有关引导（bootstrapping）或无监督 IE 的大多数研究仅使用简单的词法功能，从而避免了解析的计算量，并且少数使用无监督 IE 的系统没有比较这两种类型特征的性能。

## 架构
远程监督方法的直觉是使用 Freebase 提供一组关系和参与这些关系的实体对的训练集。在训练步骤中，使用标记个人，组织和位置的命名实体标记器在句子中标识所有实体。如果一个句子包含两个实体，而这些实体是 Freebase 关系之一的实例，则从该句子中提取特征并将其添加到该关系的特征向量中。

远程监督的假设是：**如果两个实体存在关系，则包含这两个实体的任何句子都可以表达该关系**。因为任何单个句子都可能给出错误的提示，所以作者的算法训练了多类逻辑回归分类器，为每个嘈杂特征学习权重。在训练中，来自不同句子的相同元组（关系，实体1，实体2）的特征被合并，从而创建了更丰富的特征向量。

在测试步骤中，再次使用命名的实体标记器标识实体。这次，在句子中一起出现的每对实体都被视为潜在的关系实例，每当这些实体一起出现时，就在句子上提取特征并将其添加到该实体对的特征向量中。例如，如果一对实体出现在测试集中的 10 个句子中，并且每个句子都从中提取了 3 个特征，则该实体对将具有 30 个相关特征。测试语料库中每个句子中的每个实体对都经过特征提取，然后回归分类器根据所有实体对中出现的所有句子中的特征来预测每个实体对的关联名称。

考虑位置包含关系，假设在 Freebase 中有两个关系实例：hVirginia，Richmondi 和 hFrance，Nantesi。当我们遇到“Richmond, the capital of Virginia”和“Henry’s Edict of Nantes helped the Protestants of France”这样的句子时，我们将从这些句子中提取特征。有些特征会非常有用，例如 Richmond 句子中的特征，而有些特征没那么有用，例如 Nantes 句子中的特征。 

在测试中，如果碰到“Richmond, the capital of Virginia”这样的句子，它的一个或多个特征将与 Richmond 的句子相匹配，这提供了 hAustria 和 Viennai 属于位置包含关系的证据。

作者架构的主要优势之一是它能够合并来自同一关系的许多不同的提及信息。考虑以下两个句子中的实体对 hSteven Spielberg，Single Private Ryani，作为电影与导演（film-director）关系的证据。
```
[Steven Spielberg]’s film [Saving Private
Ryan] is loosely based on the brothers’ story.

Allison co-produced the Academy Awardwinning [Saving Private Ryan], directed by
[Steven Spielberg]...
```

第一句话在为导演（film-director）提供证据的同时，也可以为导演（film-writer）或制片人（film-producer）提供证据。第二句话并没有提到《拯救大兵瑞恩》是一部电影，因此可以作为首席执行官（CEO）关系的证据（考虑“罗伯特·穆勒（Robert Mueller）指导联邦调查局”）。 孤立地看，这些特征都不是确定的，但结合起来，它们是确定的。

## 特征
作者的特征是基于语言学中的标准词汇和句法特征。每个特征都是用句法信息或非句法信息描述句子中的两个实体是如何进行关联。

### 词法特征
词法特征描述出现在句子中的两个实体之间和周围的特定单词。
- 两个实体之间的单词顺序。
- 这些词语的词性标记。
- 排在句子中第一位实体的标志。
- 实体 1 左侧 k 窗口长度的单词以及它们的词性标注。
- 实体 2 右侧 k 窗口长度的单词以及它们的词性标注。

每个词法特征都由这些内容组合而成，作者为每个 `$k \in {0,1,2}$` 生成一个合成特征，因此，表 3 中的每行都代表一个词法特征。

![Table 3](https://markdown-picture-clvsit.oss-cn-hangzhou.aliyuncs.com/distant%20supervision%20table%203.jpg)

词性标记由在 Penn Treebank 上训练的最大熵标记器进行标记，然后简化为七个类别：名词、动词、副词、形容词、数字、外来词以及其他词。

为了近似句法特征，作者测试了词法特征的变体：
1. 省略所有不是动词的单词；
2. 省略所有功能词。 

与其他词法特征结合使用时，它们对精度的提高很小，但不足以证明对计算资源的需求增加是合理的。

### 句法特征
除了词法特征外，作者还基于语法，使用依赖解析器 MINIPAR 提取特征。

依赖解析由一组单词和块（例如“Edwin Hubble”，“ Missouri”，“born”）组成，并通过方向性依赖项（例如“pred”，“lex-mod”）链接，如图 1 所示。

![Figure 1](https://markdown-picture-clvsit.oss-cn-hangzhou.aliyuncs.com/distant%20supervision%20figure%201.jpg)

从每个句子中提取每对实体的依赖路径——由一系列依赖关系、方向和表示遍历解析的单词或块组成。词性标签不包含在依赖路径中。

与 Snow 等人使用的句法特征相似，由以下两项内容结合而成：
- 两个实体之间的依赖路径。
- 对于每个实体，一个“窗口”节点不属于依赖路径。

窗口节点是链接到两个实体之一的节点，而不是依赖路径的一部分。作者为左右一对窗口节点对生成一个联合特征，并省略其中一个或两个。因此，表 3 中的每行都代表一个语法特征。

### 命名实体标签特征
除上述内容外，每个特征都包含两个实体的命名实体标签。作者使用斯坦福大学的四类命名实体标记器来进行命名实体标记。标记器为每个单词打上 {人员，位置，组织，其他，无} 的标签。

### 特征结合
作者使用联合特征，而非单独用分类器去对各个特征进行分类。每个特征都由句子的几个属性以及命名实体标签组成。要使两个特征匹配，它们的所有连词必须完全匹配，这产生了低召回率但高精度的特征。对于少量数据，此方法会出现问题，因为大多数特征只能看到一次，因此对分类器无用。由于我们使用大量数据，因此即使复杂的特征也会出现多次，从而使我们的高精度特征可以按预期工作。表 3 中显示了示例句子的特征。

## 实现
对于非结构化文本，作者使用 Freebase Wikipedia Extraction，它是所有 Wikipedia 文章（不包括讨论和用户页面）全文的转储，该文章已由 Freebase 的开发者 Metaweb Technologies 进行了句子标记。此转储包含约 180 万篇文章，每篇文章平均 14.3 个句子。单词总数（标点符号）为 601600703。对于作者的实验，作者使用了大约一半的文章：
- 训练数据：800,000 条；
- 测试数据：400,000 条。

之所以使用 Wikipedia，是因为它是相对最新的，并且句子倾向于明确表达事实，而这些事实可能会在新闻专线中被忽略。Freebase 中的许多信息均来自 Wikipedia 的表格数据，这意味着 Freebase 关系更可能出现在 Wikipedia 的句子中。

### 6.2 解析和分块
MINIPAR 解析此非结构化文本的每个句子，以生成一个依赖图。

在预处理中，具有相同命名实体标签的连续单词被“分块”，因此 Edwin/PERSON，Hubble/PERSON 变为 [Edwin Hubble]/PERSON。该分块受到句子的依存关系分析的限制。但是，因为该分块在分析中必须是连续的（即子树之间没有任何分块）。这确保必须保留分析树结构，因为必须更新分析以反映分块。

### 6.3 训练和测试
对于留出法评估实验（请参阅第 7.1 节），每种关系的一半实例未在训练中使用，后续会用于与新发现的实例进行比较。这意味着在训练中使用 900,000 个 Freebase 关系实例，并保留 900,000 个实例。这些实验在训练阶段使用了 800,000 篇 Wikipedia 文章，在测试阶段使用了 400,000 篇不同的文章。

对于人类体感评估实验，所有 180 万个关系实例都用于训练。同样，在训练阶段使用了 800,000 篇 Wikipedia 文章，在测试阶段使用了 400,000 篇不同的文章。

对所有的实验，作者仅提取训练数据中未出现的关系实例，即 Freebase 中尚未存在的实例。

为了构造分类器，系统需要负例训练数据。为此，作者在训练阶段为“无关”关系构建特征向量，方法是随机选择未出现在任何 Freebase 关系中的实体对，并为其提取特征。尽管其中某些实体对实际上可能是相关的，但从 Freebase 数据中被错误地省略了，但我们希望这些假阴性（False Negatives）平均对分类器的性能影响很小。 

出于性能原因，作者随机抽取 1％ 的此类实体对作为负例。相比之下，在实际测试数据中，提取的实体对中的 98.7％ 不具有在 Freebase 中考虑的前 102 个关系中的任何一个。

作者使用多分类逻辑分类器，该分类器使用具有高斯正则化的 L-BFGS 优化。分类器将实体对和特征向量作为输入，并基于实体对属于该关系的概率返回关系名称和置信度得分。一旦在测试中发现所有的实体对都进行了分类，就可以通过置信度得分对它们进行排序，并用于生成 n 个最有可能的新关系实例的列表。

表 4 显示了系统学习到的一些高权重特征。

![Table 4](https://markdown-picture-clvsit.oss-cn-hangzhou.aliyuncs.com/nlp/extract/distant%20supervision%20table%204.jpg)

## 7. 评估
作者通过两种方式评估标签：
- 通过在训练过程中保留部分 Freebase 关系数据来自动评估标签，然后将新发现的关系实例与该保留的数据进行比较；
- 通过人工操作人员查看每个带有正标签的实体对并标记实体对之间是否确实存在这种关系。 

两种评估都可以让我们计算出最佳 N 个实例的系统精度。

### 7.1 留出法评估
图 2 显示了分类器对保留的 Freebase 关系数据的性能。虽然留出法评估会出现假阴性（False Negatives），但它可以对精度进行粗略的衡量，而无需进行昂贵的人工评估，因此对于参数设置非常有用。

在大多数召回级别上，句法和词法特征的组合相对于其中任一特征集，其准确性都得到了实质性的提高。

![Figure 2](https://markdown-picture-clvsit.oss-cn-hangzhou.aliyuncs.com/nlp/extract/distant%20supervision%20Figure%202.jpg)

### 7.2 人工评估
人工评估是由评估人员在 Amazon 的 Mechanical Turk 服务上进行的，在 Snow 等人的研究中证明对自然语言标注有效。作者进行了三个实验：
- 仅使用句法特征；
- 仅使用词法特征；
- 同时使用句法和词法特征。 

对于测试数据中最频繁出现的 10 个关系中的每一个（根据分类器），我们从每个实验中生成该关系的前 100 个和 1000 个实例中抽取样本，并将其发送给Mechanical Turk进行人工评估。样本量为 100。

在 Mechanical Turk 上，每个预测的关系实例都由 1-3 个标记器标记为是或否。根据标签的多数票确定了每种关系的真假。在平局的情况下（每种方式一票），以相等的概率将关系指定为真或假。表 5 给出了在召回 100 个和 1000 个实例时对句法，词法和特征组合的评估。

![Table 5](https://markdown-picture-clvsit.oss-cn-hangzhou.aliyuncs.com/nlp/extract/distant%20supervision%20table%205.jpg)

在召回 100 个实例时，词法和句法特征的组合在大多数关系中表现最佳，而在召回级别为 1000 的情况下，结果是复杂的。在所有关系中，没有任何一个特征集比任何其他特征集都有明显的优势。

## 8. 讨论
作者的结果表明，远程监督算法能够提取合理数量的关系的高精度模式。

图 2 中保留的结果表明，句法和词法特征的组合比单独的任何一个特征集提供更好的性能。为了理解句法功能的作用，作者检查了表 5 中最常见的 10 种关系的人为评价。对于每个关系中排名最高的 100 个实例，大多数最佳结果都是单独使用或与词法特征结合使用句法特征。对于每个关系中排名最高的 1000 个实例，结果的混合程度更高，但句法特征在大多数分类中仍然有所帮助。

然后，作者研究句法特征似乎有助于解决的那些关系。例如，对于导演电影和作家电影关系，句法特征始终胜过词法特征。如第 4 节所述，这两种关系特别含糊不清，表明句法特征可以帮助弄清困难的关系。也许更能说明问题的是，我们注意到导演和电影之间长串的例子：
```
Back Street is a 1932 film made by Universal Pictures, directed by John M. Stahl, and
produced by Carl Laemmle Jr.
```

这样的句子具有很长（因此很少见）的词法特征，但是依赖路径相对较短。语法特征可以更容易地从构成这些字符串的过渡部分的语法修饰符中抽象出来。

因此，结果表明，句法特征在远程监督信息抽取中确实有用，并且在单个模式特别模棱两可，且它们在依存结构中距离较近但距离较远的情况下，句法的好处是会出现的。 

未来的工作还有待观察，是否更简单的基于块的语法功能可能能够在没有完整解析的开销的情况下捕获足够的这种收益，以及共指解析是否可以提高性能。
